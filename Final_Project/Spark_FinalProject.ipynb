{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52138a4e-e26e-4aae-9fbe-0ceee0af29aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###   1.Load all IMDb datasets from DBFS using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5277242-ab3d-429f-b998-9ad7a9da342a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load all IMDb datasets from DBFS using Spark\n",
    "\n",
    "title_principals_df = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv(\n",
    "    \"dbfs:/FileStore/shared_uploads/jilson.jose@edu.ece.fr/title_principals_tsv-1.gz\"\n",
    ")\n",
    "\n",
    "title_akas_df = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv(\n",
    "    \"dbfs:/FileStore/shared_uploads/jilson.jose@edu.ece.fr//title_akas_tsv-1.gz\"\n",
    ")\n",
    "\n",
    "title_basics_df = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv(\n",
    "    \"dbfs:/FileStore/shared_uploads/jilson.jose@edu.ece.fr/title_basics_tsv-1.gz\"\n",
    ")\n",
    "\n",
    "name_basics_df = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv(\n",
    "    \"dbfs:/FileStore/shared_uploads/jilson.jose@edu.ece.fr/name_basics_tsv-1.gz\"\n",
    ")\n",
    "\n",
    "title_crew_df = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv(\n",
    "    \"dbfs:/FileStore/shared_uploads/jilson.jose@edu.ece.fr/title_crew_tsv-1.gz\"\n",
    ")\n",
    "\n",
    "title_episode_df = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv(\n",
    "    \"dbfs:/FileStore/shared_uploads/jilson.jose@edu.ece.fr/title_episode_tsv-1.gz\"\n",
    ")\n",
    "\n",
    "title_ratings_df = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").csv(\n",
    "    \"dbfs:/FileStore/shared_uploads/jilson.jose@edu.ece.fr/title_ratings_tsv-1.gz\"\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3778b2a-040d-4fdb-9d30-9fc524ad3c28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.How many total people in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7389019f-1eb0-4c3d-aeda-281a0ac9daea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total people: 14315377\n"
     ]
    }
   ],
   "source": [
    "total_people = name_basics_df.select(\"nconst\").distinct().count()\n",
    "print(f\"Total people: {total_people}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13b5efb0-7c2a-45ee-83e4-1e47bec9139d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.what is the earliest year of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f5a6a64-b047-4d49-bd2b-ace646425c9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest birth year: 1048 by Omar Khayyam\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter valid numeric years\n",
    "birth_years_df = name_basics_df.filter(col(\"birthYear\").rlike(\"^\\d{4}$\")).withColumn(\"birthYear\", col(\"birthYear\").cast(\"int\"))\n",
    "earliest_birth = birth_years_df.orderBy(\"birthYear\").select(\"primaryName\", \"birthYear\").first()\n",
    "print(f\"Earliest birth year: {earliest_birth['birthYear']} by {earliest_birth['primaryName']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "124e00da-1e0b-4b2a-8e5b-d66bbea59020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.how many years ago was this person born"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fa87e0e-08c3-4972-a622-7f572019f657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omar Khayyam was born 977 years ago.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current_year = datetime.now().year\n",
    "years_ago = current_year - earliest_birth[\"birthYear\"]\n",
    "print(f\"{earliest_birth['primaryName']} was born {years_ago} years ago.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab34310-de31-4752-bf23-52b4412b2f0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5.using only the data in the data set is this date of birth correct . explain the answer\n",
    "**Answer:** From the data alone, we can't make claims of correctness. However, in the event that this person worked in productions during the early 1900s, the birth year is reasonable and consistent within itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0306fdfd-d6f7-45b4-852c-457a6902e129",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6.what is the latest data of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "687f48f9-d838-478c-bbbf-b390c9aacc25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest birth year: 2024 by Ronnie Lordi\n"
     ]
    }
   ],
   "source": [
    "latest_birth = birth_years_df.orderBy(col(\"birthYear\").desc()).select(\"primaryName\", \"birthYear\").first()\n",
    "print(f\"Latest birth year: {latest_birth['birthYear']} by {latest_birth['primaryName']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f18eb4e-379e-447c-96fb-27b0dd1679b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 7.how many people do not have a year of birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7257fd3-0a6c-4115-8834-5743c33a348d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People without birth year: 13672818\n"
     ]
    }
   ],
   "source": [
    "missing_births = name_basics_df.filter((col(\"birthYear\") == \"\\\\N\") | col(\"birthYear\").isNull()).count()\n",
    "print(f\"People without birth year: {missing_births}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f188f60e-2030-45bf-ad57-93bc8816436b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 8.what is the length of the longest short after 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d31de08c-b266-4492-a15d-eeb26cce7063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest short after 1900: Project Bolo (400 min)\n"
     ]
    }
   ],
   "source": [
    "shorts_df = title_basics_df.filter(\n",
    "    (col(\"genres\").contains(\"Short\")) & \n",
    "    (col(\"startYear\").rlike(\"^\\d{4}$\")) & \n",
    "    (col(\"runtimeMinutes\").rlike(\"^\\d+$\"))\n",
    ").withColumn(\"startYear\", col(\"startYear\").cast(\"int\")).withColumn(\"runtimeMinutes\", col(\"runtimeMinutes\").cast(\"int\"))\n",
    "\n",
    "longest_short = shorts_df.filter(col(\"startYear\") > 1900).orderBy(col(\"runtimeMinutes\").desc()).select(\"primaryTitle\", \"runtimeMinutes\").first()\n",
    "print(f\"Longest short after 1900: {longest_short['primaryTitle']} ({longest_short['runtimeMinutes']} min)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34fb6fd8-b26c-47d9-9d09-899e7ac0833c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 9.what is the length of the shortest movie after 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea3e538d-bfe7-4164-8e69-6c4e280b803a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest movie after 1900: Storm P. tegner de Tree Små Mænd (0 min)\nShortest movie after 1900 Excluding O Minutes: What Came Out of the Cheese; or, The Lilliputians in a New York Restaurant (1 min)\n"
     ]
    }
   ],
   "source": [
    "movies_df = title_basics_df.filter(\n",
    "    (col(\"startYear\").rlike(\"^\\d{4}$\")) & \n",
    "    (col(\"runtimeMinutes\").rlike(\"^\\d+$\"))\n",
    ").withColumn(\"startYear\", col(\"startYear\").cast(\"int\")).withColumn(\"runtimeMinutes\", col(\"runtimeMinutes\").cast(\"int\"))\n",
    "\n",
    "shortest_movie = movies_df.filter(col(\"startYear\") > 1900).orderBy(\"runtimeMinutes\").select(\"primaryTitle\", \"runtimeMinutes\").first()\n",
    "print(f\"Shortest movie after 1900: {shortest_movie['primaryTitle']} ({shortest_movie['runtimeMinutes']} min)\")\n",
    "# Filter out runtimeMinutes == 0\n",
    "movies_df = movies_df.filter((col(\"startYear\") > 1900) & (col(\"runtimeMinutes\") > 0))\n",
    "\n",
    "shortest_movie = movies_df.orderBy(\"runtimeMinutes\").select(\"primaryTitle\", \"runtimeMinutes\").first()\n",
    "\n",
    "print(f\"Shortest movie after 1900 Excluding O Minutes: {shortest_movie['primaryTitle']} ({shortest_movie['runtimeMinutes']} min)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cb4d5b4-7583-4dbf-b04a-3a65e1ea8905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 10.provide a list of all of the genres represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5ae5a29-af64-42a8-998f-0b659f4d4657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|genre      |\n+-----------+\n|Action     |\n|Adult      |\n|Adventure  |\n|Animation  |\n|Biography  |\n|Comedy     |\n|Crime      |\n|Documentary|\n|Drama      |\n|Family     |\n|Fantasy    |\n|Film-Noir  |\n|Game-Show  |\n|History    |\n|Horror     |\n|Music      |\n|Musical    |\n|Mystery    |\n|News       |\n|Reality-TV |\n+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, split\n",
    "\n",
    "genres_df = title_basics_df.select(split(col(\"genres\"), \",\").alias(\"genre_list\"))\n",
    "distinct_genres = genres_df.select(explode(\"genre_list\").alias(\"genre\")).distinct().orderBy(\"genre\")\n",
    "distinct_genres.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf14a59a-c12c-448b-9b33-23e395cc9e37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 11.what is the higest rated comedy movie in the dataset . note, if there is a tie, the tie shall be broken by the movie with the most votes ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7dd86ea-cf19-499d-8a6b-db6663e72d58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top comedy: I challenge the Ender Dragon in Minecraft (Ending) (10.0 ⭐, 320 votes)\n"
     ]
    }
   ],
   "source": [
    "# Clean and join\n",
    "ratings_clean = title_ratings_df.withColumn(\"averageRating\", col(\"averageRating\").cast(\"float\")) \\\n",
    "                                 .withColumn(\"numVotes\", col(\"numVotes\").cast(\"int\"))\n",
    "\n",
    "comedy_movies_df = title_basics_df.filter(col(\"genres\").contains(\"Comedy\"))\n",
    "comedy_ratings_df = comedy_movies_df.join(ratings_clean, on=\"tconst\", how=\"inner\")\n",
    "\n",
    "# Sort by rating and votes\n",
    "top_comedy = comedy_ratings_df.orderBy(col(\"averageRating\").desc(), col(\"numVotes\").desc()).select(\"tconst\", \"primaryTitle\", \"averageRating\", \"numVotes\").first()\n",
    "print(f\"Top comedy: {top_comedy['primaryTitle']} ({top_comedy['averageRating']} ⭐, {top_comedy['numVotes']} votes)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "562a2121-d618-4ca7-8d46-1cc34ade8dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 12.who was the director of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c40f130a-87c0-4d7f-8204-54fc0948b94a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Director(s): Felix Kjellberg\n"
     ]
    }
   ],
   "source": [
    "# Get director using title_crew\n",
    "director_row = title_crew_df.filter(col(\"tconst\") == top_comedy[\"tconst\"]).select(\"directors\").first()\n",
    "\n",
    "if director_row and director_row[\"directors\"] != \"\\\\N\":\n",
    "    director_ids = director_row[\"directors\"].split(\",\")\n",
    "    directors = name_basics_df.filter(col(\"nconst\").isin(director_ids)).select(\"primaryName\").rdd.flatMap(lambda x: x).collect()\n",
    "    print(f\"Director(s): {', '.join(directors)}\")\n",
    "else:\n",
    "    print(\"No director listed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad4de8cc-d450-4168-a4a0-b9f061f3dd11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 13.List, if any, the alternate titles for the movie ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3faf6879-2953-4aa6-bd1e-2fa02a0287b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternate titles: I challenge the Ender Dragon in Minecraft (Ending)\n"
     ]
    }
   ],
   "source": [
    "alt_titles = title_akas_df.filter(col(\"titleId\") == top_comedy[\"tconst\"]).select(\"title\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "print(f\"Alternate titles: {', '.join(alt_titles)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ef2601e-db09-48f5-9387-18fb3b4b145d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Degrees of seperation\n",
    "A degree of separation is a way to measure how far apart two people (in this case, actors) are from each other in a network, based on their connections.\n",
    "\n",
    "Here's a simple explanation:\n",
    "\n",
    "1st Degree: Direct connection\n",
    "\n",
    "If Actor A and Actor B have worked together in a movie, they have 1 degree of separation Example: Tom Hanks and Tim Allen worked together in \"Toy Story\", so they are 1 degree apart\n",
    "2nd Degree: Connection through one intermediary\n",
    "\n",
    "If Actor A worked with Actor B, and Actor B worked with Actor C (but A never worked with C), then A and C have 2 degrees of separation Example: If Tom Hanks worked with Julia Roberts, and Julia Roberts worked with George Clooney (but Tom Hanks never worked with Clooney), then Hanks and Clooney are 2 degrees apart\n",
    "3rd Degree: Connection through two intermediaries\n",
    "\n",
    "Continues the chain with one more person in between Example: Actor A → Actor B → Actor C → Actor D\n",
    "Explore the degrees of seperation for nconst nm0000102 to the 6th Degree . Please note, you may need to persist each degree of seperation to permanent storage as the community edition may not have the resources to do the calculations in one run ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5440ec81-bd04-4c3f-9fc2-8d3cf24391da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Build Actor-Movie Pairs and Build the Actor-to-Actor Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd5b2205-e22c-4b94-b8ea-8b00fb7768ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Only keep actors and actresses\n",
    "actor_movie_df = title_principals_df.filter(\n",
    "    col(\"category\").isin(\"actor\", \"actress\")\n",
    ").select(\"tconst\", \"nconst\").distinct()\n",
    "\n",
    "actor_edges_df = actor_movie_df.alias(\"a\").join(\n",
    "    actor_movie_df.alias(\"b\"),\n",
    "    on=\"tconst\"\n",
    ").filter(col(\"a.nconst\") != col(\"b.nconst\")) \\\n",
    " .select(col(\"a.nconst\").alias(\"from_actor\"), col(\"b.nconst\").alias(\"to_actor\")).distinct()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0695ae-3c22-4d2b-a0ca-34965c07b7c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  BFS - Degree of Separation from Kevin Bacon\n",
    "###  14.Build the degrees of seperation . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "258b6cc6-9c5f-483b-8eee-d1ba9768f72c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1 saved.\nDegree 2 saved.\nDegree 3 saved.\nDegree 4 saved.\nDegree 5 saved.\nDegree 6 saved.\n"
     ]
    }
   ],
   "source": [
    "# Start with Kevin Bacon\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Degree 0: Kevin Bacon himself\n",
    "degree_0 = spark.createDataFrame([(\"nm0000102\", 0)], [\"nconst\", \"degree\"])\n",
    "\n",
    "# Save initial degree\n",
    "degree_0.write.mode(\"overwrite\").parquet(\"/tmp/degree_0\")\n",
    "\n",
    "# Build BFS levels 1 to 6\n",
    "current_level = degree_0\n",
    "for i in range(1, 7):\n",
    "    prev_level = spark.read.parquet(f\"/tmp/degree_{i - 1}\")\n",
    "    # Join edges to expand\n",
    "    next_level = prev_level.join(actor_edges_df, prev_level.nconst == actor_edges_df.from_actor, how=\"inner\") \\\n",
    "        .select(col(\"to_actor\").alias(\"nconst\")).distinct()\n",
    "\n",
    "    # Remove already visited\n",
    "    visited = spark.read.parquet(f\"/tmp/degree_0\")\n",
    "    for j in range(1, i):\n",
    "        visited = visited.union(spark.read.parquet(f\"/tmp/degree_{j}\"))\n",
    "    next_level = next_level.join(visited, on=\"nconst\", how=\"left_anti\")\n",
    "\n",
    "    # Add degree info\n",
    "    next_level = next_level.withColumn(\"degree\", lit(i))\n",
    "\n",
    "    # Save to storage\n",
    "    next_level.write.mode(\"overwrite\").parquet(f\"/tmp/degree_{i}\")\n",
    "    print(f\"Degree {i} saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bba04e2-54fe-4c5d-b52f-94f07ef70b0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree counts: [(0, 1), (1, 888), (2, 107313), (3, 1124643), (4, 1440871), (5, 315279), (6, 48052)]\nMost people: Degree 4 (1440871)\nMost (excluding Degree 0): Degree 3 (1124643)\nLeast people: Degree 0 (1)\n"
     ]
    }
   ],
   "source": [
    "degree_counts = []\n",
    "for i in range(7):\n",
    "    df = spark.read.parquet(f\"/tmp/degree_{i}\")\n",
    "    count = df.count()\n",
    "    degree_counts.append((i, count))\n",
    "\n",
    "sorted_counts = sorted(degree_counts, key=lambda x: x[1], reverse=True)\n",
    "print(\"Degree counts:\", degree_counts)\n",
    "\n",
    "most = sorted_counts[0]\n",
    "most_excluding_zero = sorted_counts[1]\n",
    "least = sorted_counts[-1]\n",
    "print(f\"Most people: Degree {most[0]} ({most[1]})\")\n",
    "print(f\"Most (excluding Degree 0): Degree {most_excluding_zero[0]} ({most_excluding_zero[1]})\")\n",
    "print(f\"Least people: Degree {least[0]} ({least[1]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6c0c971-62b7-4787-9a54-be7bb8c62ccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 15.Which degree contains the most people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e3b3a3c-6e42-4965-85d5-6ffddd6c5fa5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 0: 1 people\nDegree 1: 888 people\nDegree 2: 107313 people\nDegree 3: 1124643 people\nDegree 4: 1440871 people\nDegree 5: 315279 people\nDegree 6: 48052 people\n\n Most people overall: Degree 4 with 1440871 people\n"
     ]
    }
   ],
   "source": [
    "degree_counts = []\n",
    "for i in range(7):\n",
    "    df = spark.read.parquet(f\"/tmp/degree_{i}\")\n",
    "    count = df.count()\n",
    "    degree_counts.append((i, count))\n",
    "    print(f\"Degree {i}: {count} people\")\n",
    "\n",
    "# Find the max\n",
    "most = max(degree_counts, key=lambda x: x[1])\n",
    "print(f\"\\n Most people overall: Degree {most[0]} with {most[1]} people\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7312a09-5327-43f9-b36e-440f1582872d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 16.Aside from Degree 0, which degree contains the most people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b7cabcd-6133-4f84-a098-965e44644e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Most people (excluding Degree 0): Degree 4 with 1440871 people\n"
     ]
    }
   ],
   "source": [
    "# Exclude degree 0\n",
    "most_excl_0 = max(degree_counts[1:], key=lambda x: x[1])\n",
    "print(f\" Most people (excluding Degree 0): Degree {most_excl_0[0]} with {most_excl_0[1]} people\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d800f3fe-80c7-4740-bb36-2aec6c2e919d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 17.Which contains the least ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddbbcb68-4844-4638-9eb8-ec127d6a5023",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Least people (including Degree 0): Degree 0 with 1 people\nLeast people (excluding Degree 0): Degree 1 with 888 people\n"
     ]
    }
   ],
   "source": [
    "least = min(degree_counts, key=lambda x: x[1])\n",
    "print(f\" Least people (including Degree 0): Degree {least[0]} with {least[1]} people\")\n",
    "# Exclude degree 0\n",
    "least = min(degree_counts[1:], key=lambda x: x[1])\n",
    "print(f\"Least people (excluding Degree 0): Degree {least[0]} with {least[1]} people\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e01b82fb-45d6-406e-a946-a8e91fef451d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 18.Is the person from question 3 within 6 Degrees of nm0000102, if so, how many ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "509d2043-ba24-4b78-8d32-c56ebf866f99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omar Khayyam is NOT within 6 degrees.\n"
     ]
    }
   ],
   "source": [
    "earliest_nconst =  earliest_birth['primaryName']\n",
    "\n",
    "found = False\n",
    "for i in range(1, 7):\n",
    "    df = spark.read.parquet(f\"/tmp/degree_{i}\")\n",
    "    if df.filter(col(\"nconst\") == earliest_nconst).count() > 0:\n",
    "        print(f\"{earliest_nconst} is within {i} degrees of Kevin Bacon.\")\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    print(f\"{earliest_nconst} is NOT within 6 degrees.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d76f4e5d-5fd4-4048-b78c-d1b3c6081058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Which degree contains the least people?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "159c1245-7756-4dee-bcab-1fb01dc40301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 19.Is nm0000102 within 6 degrees of the movie from question 11, if so, how many ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d259e48d-3e50-4ae8-bdaf-cefecf82b937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin Bacon is NOT within 6 degrees of the comedy movie.\n"
     ]
    }
   ],
   "source": [
    "top_comedy_tconst = top_comedy['primaryTitle']\n",
    "\n",
    "comedy_actors = title_principals_df.filter(\n",
    "    (col(\"tconst\") == top_comedy_tconst) &\n",
    "    (col(\"category\").isin(\"actor\", \"actress\"))\n",
    ").select(\"nconst\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "for i in range(1, 7):\n",
    "    df = spark.read.parquet(f\"/tmp/degree_{i}\")\n",
    "    overlap = df.filter(col(\"nconst\").isin(comedy_actors))\n",
    "    if overlap.count() > 0:\n",
    "        print(f\"Kevin Bacon is within {i} degrees of top comedy movie actors.\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Kevin Bacon is NOT within 6 degrees of the comedy movie.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79ac9c0f-0574-4982-aecd-00e57dfc47c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SparkProject",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}